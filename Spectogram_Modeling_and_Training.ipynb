{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.1"
    },
    "colab": {
      "name": "Spectogram Modeling and Training.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "4U3Q9VMa9Xds"
      },
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow.keras\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, Flatten\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, LSTM\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.preprocessing import image\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tqdm import tqdm\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.preprocessing import OneHotEncoder"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mW7RyCpn9Xd5"
      },
      "source": [
        "train = pd.read_csv(r\"C:\\Users\\Prawar Narang\\image_spec.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xb5wt0VJ9XeE",
        "outputId": "79e6ebbf-b6d7-43e2-c390-d5a1940cb1ca"
      },
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
        "\n",
        "\n",
        "datagen = ImageDataGenerator(\n",
        "        rotation_range=40,\n",
        "        width_shift_range=0.2,\n",
        "        height_shift_range=0.2,\n",
        "        shear_range=0.2,\n",
        "        zoom_range=0.2,\n",
        "        horizontal_flip=True,\n",
        "        fill_mode='nearest')\n",
        "                     \n",
        "\n",
        "train_image = []\n",
        "for i in tqdm(range(train.shape[0])):\n",
        "    img = image.load_img(train['iname'][i], target_size=(28,28,3), grayscale=False)\n",
        "    img = image.img_to_array(img)\n",
        "    img = img/255\n",
        "    train_image.append(img)\n",
        "X = np.array(train_image)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|███████████████████████████████████████████████████████████████████████████████| 461/461 [00:01<00:00, 256.63it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gviVrObg9XeO"
      },
      "source": [
        "le = LabelEncoder() \n",
        "  \n",
        "train['label'] = le.fit_transform(train['label']) \n",
        "\n",
        "y=train['label'].values\n",
        "y = to_categorical(y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RWQve9oj9XeX"
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=75, test_size=0.25, shuffle = True)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mbZP4c_N9Xef"
      },
      "source": [
        "datagen.fit(X_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1oKSrb6w9Xem"
      },
      "source": [
        "x_train = np.array(X_train).reshape((345, 28, -1))\n",
        "x_test = np.array(X_test).reshape((116, 28, -1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o82dDmSI9Xeu",
        "outputId": "258c5784-77e2-477f-b55e-fda9a7d33611"
      },
      "source": [
        "print('X_train shape:', X_train.shape)\n",
        "print(X_train.shape[0], 'train samples')\n",
        "print(X_test.shape[0], 'test samples')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X_train shape: (345, 28, 28, 3)\n",
            "345 train samples\n",
            "116 test samples\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k-6yImp79Xe0"
      },
      "source": [
        "from tensorflow.keras.layers import TimeDistributed\n",
        "from tensorflow.keras.layers import AveragePooling1D\n",
        "from tensorflow.keras.losses import categorical_crossentropy\n",
        "from tensorflow.keras.optimizers import RMSprop"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_shfrnYI9Xe4"
      },
      "source": [
        "batch_size = 128\n",
        "nb_epoch = 100\n",
        "\n",
        "# Parameters for MNIST dataset\n",
        "img_rows, img_cols = 28, 28\n",
        "nb_classes = 3\n",
        "\n",
        "# Parameters for LSTM network\n",
        "nb_lstm_outputs = 30\n",
        "nb_time_steps = img_rows\n",
        "dim_input_vector = img_cols"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rce-V7Ny9Xe-"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(LSTM(64, input_shape=(28, 84), return_sequences=True, implementation=2))\n",
        "model.add(TimeDistributed(Dense(1)))\n",
        "model.add(AveragePooling1D())\n",
        "\n",
        "model.add(Flatten())\n",
        "\n",
        "model.add(Dense(3, activation='softmax'))\n",
        "model.compile(loss=categorical_crossentropy, optimizer=RMSprop(lr=.01),metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kLQ41QL19XfE",
        "outputId": "21cbc11d-6545-4860-f181-a97dc8ce1797"
      },
      "source": [
        "# Train\n",
        "history = model.fit(x_train, y_train, epochs=nb_epoch, batch_size=batch_size, shuffle=True, verbose=1, validation_data=(x_test, y_test))\n",
        "\n",
        "# EvaluateX_train, y_train, epochs=35, validation_data=(X_test, y_test)\n",
        "evaluation = model.evaluate(x_test, y_test, batch_size=batch_size, verbose=1)\n",
        "print('Summary: Loss over the test dataset: %.2f, Accuracy: %.2f' % (evaluation[0], evaluation[1]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 345 samples, validate on 116 samples\n",
            "Epoch 1/100\n",
            "345/345 [==============================] - ETA: 2s - loss: 1.0956 - acc: 0.289 - ETA: 0s - loss: 2.6277 - acc: 0.222 - 2s 6ms/sample - loss: 2.2383 - acc: 0.2058 - val_loss: 1.0782 - val_acc: 0.1638\n",
            "Epoch 2/100\n",
            "345/345 [==============================] - ETA: 0s - loss: 1.0871 - acc: 0.210 - ETA: 0s - loss: 1.0588 - acc: 0.402 - 0s 663us/sample - loss: 1.0348 - acc: 0.4783 - val_loss: 0.9086 - val_acc: 0.7672\n",
            "Epoch 3/100\n",
            "345/345 [==============================] - ETA: 0s - loss: 0.9593 - acc: 0.664 - ETA: 0s - loss: 0.9330 - acc: 0.671 - 0s 724us/sample - loss: 0.9379 - acc: 0.6551 - val_loss: 0.7611 - val_acc: 0.7672\n",
            "Epoch 4/100\n",
            "345/345 [==============================] - ETA: 0s - loss: 0.8367 - acc: 0.695 - ETA: 0s - loss: 0.8782 - acc: 0.656 - 0s 589us/sample - loss: 0.8697 - acc: 0.6696 - val_loss: 0.7062 - val_acc: 0.7672\n",
            "Epoch 5/100\n",
            "345/345 [==============================] - ETA: 0s - loss: 0.8053 - acc: 0.718 - ETA: 0s - loss: 0.8484 - acc: 0.671 - 0s 545us/sample - loss: 0.8524 - acc: 0.6696 - val_loss: 0.6998 - val_acc: 0.7672\n",
            "Epoch 6/100\n",
            "345/345 [==============================] - ETA: 0s - loss: 0.9483 - acc: 0.593 - ETA: 0s - loss: 0.8829 - acc: 0.664 - 0s 1ms/sample - loss: 0.8662 - acc: 0.6696 - val_loss: 0.7034 - val_acc: 0.7672\n",
            "Epoch 7/100\n",
            "345/345 [==============================] - ETA: 0s - loss: 0.8215 - acc: 0.671 - ETA: 0s - loss: 0.8448 - acc: 0.671 - 0s 1ms/sample - loss: 0.8497 - acc: 0.6696 - val_loss: 0.7106 - val_acc: 0.7672\n",
            "Epoch 8/100\n",
            "345/345 [==============================] - ETA: 0s - loss: 0.9395 - acc: 0.593 - ETA: 0s - loss: 0.8659 - acc: 0.664 - 0s 905us/sample - loss: 0.8594 - acc: 0.6696 - val_loss: 0.7228 - val_acc: 0.7672\n",
            "Epoch 9/100\n",
            "345/345 [==============================] - ETA: 0s - loss: 0.8403 - acc: 0.671 - ETA: 0s - loss: 0.8576 - acc: 0.656 - 0s 618us/sample - loss: 0.8443 - acc: 0.6696 - val_loss: 0.6842 - val_acc: 0.7672\n",
            "Epoch 10/100\n",
            "345/345 [==============================] - ETA: 0s - loss: 0.8761 - acc: 0.632 - ETA: 0s - loss: 0.8879 - acc: 0.640 - 0s 535us/sample - loss: 0.8558 - acc: 0.6696 - val_loss: 0.6792 - val_acc: 0.7672\n",
            "Epoch 11/100\n",
            "345/345 [==============================] - ETA: 0s - loss: 0.8424 - acc: 0.695 - ETA: 0s - loss: 0.8535 - acc: 0.668 - 0s 573us/sample - loss: 0.8478 - acc: 0.6696 - val_loss: 0.6977 - val_acc: 0.7672\n",
            "Epoch 12/100\n",
            "345/345 [==============================] - ETA: 0s - loss: 0.9363 - acc: 0.617 - ETA: 0s - loss: 0.8996 - acc: 0.644 - 0s 549us/sample - loss: 0.8542 - acc: 0.6696 - val_loss: 0.6782 - val_acc: 0.7672\n",
            "Epoch 13/100\n",
            "345/345 [==============================] - ETA: 0s - loss: 0.9052 - acc: 0.648 - ETA: 0s - loss: 0.8904 - acc: 0.648 - 0s 528us/sample - loss: 0.8575 - acc: 0.6696 - val_loss: 0.6840 - val_acc: 0.7672\n",
            "Epoch 14/100\n",
            "345/345 [==============================] - ETA: 0s - loss: 0.7687 - acc: 0.710 - ETA: 0s - loss: 0.8104 - acc: 0.679 - 0s 581us/sample - loss: 0.8401 - acc: 0.6696 - val_loss: 0.7496 - val_acc: 0.7672\n",
            "Epoch 15/100\n",
            "345/345 [==============================] - ETA: 0s - loss: 0.8771 - acc: 0.664 - ETA: 0s - loss: 0.8221 - acc: 0.691 - 0s 552us/sample - loss: 0.8607 - acc: 0.6696 - val_loss: 0.7803 - val_acc: 0.7672\n",
            "Epoch 16/100\n",
            "345/345 [==============================] - ETA: 0s - loss: 0.8302 - acc: 0.703 - ETA: 0s - loss: 0.8309 - acc: 0.687 - 0s 558us/sample - loss: 0.8495 - acc: 0.6696 - val_loss: 0.7369 - val_acc: 0.7672\n",
            "Epoch 17/100\n",
            "345/345 [==============================] - ETA: 0s - loss: 0.8220 - acc: 0.671 - ETA: 0s - loss: 0.8345 - acc: 0.668 - 0s 630us/sample - loss: 0.8337 - acc: 0.6696 - val_loss: 0.6960 - val_acc: 0.7672\n",
            "Epoch 18/100\n",
            "345/345 [==============================] - ETA: 0s - loss: 0.8448 - acc: 0.648 - ETA: 0s - loss: 0.8420 - acc: 0.648 - 0s 584us/sample - loss: 0.8229 - acc: 0.6696 - val_loss: 0.6867 - val_acc: 0.7672\n",
            "Epoch 19/100\n",
            "345/345 [==============================] - ETA: 0s - loss: 0.8137 - acc: 0.679 - ETA: 0s - loss: 0.8437 - acc: 0.656 - 0s 536us/sample - loss: 0.8380 - acc: 0.6696 - val_loss: 0.7170 - val_acc: 0.7672\n",
            "Epoch 20/100\n",
            "345/345 [==============================] - ETA: 0s - loss: 0.6904 - acc: 0.765 - ETA: 0s - loss: 0.8729 - acc: 0.683 - 0s 603us/sample - loss: 0.8696 - acc: 0.6696 - val_loss: 0.7494 - val_acc: 0.7672\n",
            "Epoch 21/100\n",
            "345/345 [==============================] - ETA: 0s - loss: 0.8684 - acc: 0.648 - ETA: 0s - loss: 0.8251 - acc: 0.660 - 0s 580us/sample - loss: 0.8239 - acc: 0.6696 - val_loss: 0.6823 - val_acc: 0.7672\n",
            "Epoch 22/100\n",
            "345/345 [==============================] - ETA: 0s - loss: 0.8642 - acc: 0.648 - ETA: 0s - loss: 0.8180 - acc: 0.668 - 0s 583us/sample - loss: 0.8134 - acc: 0.6696 - val_loss: 0.6980 - val_acc: 0.7672\n",
            "Epoch 23/100\n",
            "345/345 [==============================] - ETA: 0s - loss: 0.7733 - acc: 0.656 - ETA: 0s - loss: 0.7658 - acc: 0.691 - 0s 573us/sample - loss: 0.7699 - acc: 0.6812 - val_loss: 0.7326 - val_acc: 0.7328\n",
            "Epoch 24/100\n",
            "345/345 [==============================] - ETA: 0s - loss: 0.7622 - acc: 0.734 - ETA: 0s - loss: 0.7228 - acc: 0.726 - 0s 557us/sample - loss: 0.7587 - acc: 0.6928 - val_loss: 0.7031 - val_acc: 0.7672\n",
            "Epoch 25/100\n",
            "345/345 [==============================] - ETA: 0s - loss: 0.8482 - acc: 0.656 - ETA: 0s - loss: 0.8126 - acc: 0.683 - 0s 606us/sample - loss: 0.8079 - acc: 0.6725 - val_loss: 0.7546 - val_acc: 0.7241\n",
            "Epoch 26/100\n",
            "345/345 [==============================] - ETA: 0s - loss: 0.7129 - acc: 0.750 - ETA: 0s - loss: 0.7281 - acc: 0.718 - 0s 598us/sample - loss: 0.7241 - acc: 0.7159 - val_loss: 0.7223 - val_acc: 0.7672\n",
            "Epoch 27/100\n",
            "345/345 [==============================] - ETA: 0s - loss: 0.8383 - acc: 0.625 - ETA: 0s - loss: 0.7546 - acc: 0.675 - 0s 584us/sample - loss: 0.7463 - acc: 0.6928 - val_loss: 0.7263 - val_acc: 0.7586\n",
            "Epoch 28/100\n",
            "345/345 [==============================] - ETA: 0s - loss: 0.7306 - acc: 0.687 - ETA: 0s - loss: 0.7122 - acc: 0.687 - 0s 556us/sample - loss: 0.6831 - acc: 0.7159 - val_loss: 0.8010 - val_acc: 0.7241\n",
            "Epoch 29/100\n",
            "345/345 [==============================] - ETA: 0s - loss: 0.7021 - acc: 0.695 - ETA: 0s - loss: 0.6822 - acc: 0.703 - 0s 580us/sample - loss: 0.6812 - acc: 0.7072 - val_loss: 1.0167 - val_acc: 0.6034\n",
            "Epoch 30/100\n",
            "345/345 [==============================] - ETA: 0s - loss: 0.7423 - acc: 0.671 - ETA: 0s - loss: 0.7408 - acc: 0.675 - 0s 556us/sample - loss: 0.7387 - acc: 0.6928 - val_loss: 0.8163 - val_acc: 0.6810\n",
            "Epoch 31/100\n",
            "345/345 [==============================] - ETA: 0s - loss: 0.5986 - acc: 0.765 - ETA: 0s - loss: 0.6509 - acc: 0.726 - 0s 603us/sample - loss: 0.6477 - acc: 0.7362 - val_loss: 0.9407 - val_acc: 0.6552\n",
            "Epoch 32/100\n",
            "345/345 [==============================] - ETA: 0s - loss: 0.7749 - acc: 0.664 - ETA: 0s - loss: 0.7640 - acc: 0.664 - 0s 531us/sample - loss: 0.7376 - acc: 0.6899 - val_loss: 0.7553 - val_acc: 0.7414\n",
            "Epoch 33/100\n",
            "345/345 [==============================] - ETA: 0s - loss: 0.5950 - acc: 0.781 - ETA: 0s - loss: 0.5814 - acc: 0.781 - 0s 605us/sample - loss: 0.6045 - acc: 0.7681 - val_loss: 0.7719 - val_acc: 0.7414\n",
            "Epoch 34/100\n",
            "345/345 [==============================] - ETA: 0s - loss: 0.6682 - acc: 0.718 - ETA: 0s - loss: 0.6116 - acc: 0.753 - 0s 541us/sample - loss: 0.6027 - acc: 0.7652 - val_loss: 1.0807 - val_acc: 0.5776\n",
            "Epoch 35/100\n",
            "345/345 [==============================] - ETA: 0s - loss: 0.6374 - acc: 0.742 - ETA: 0s - loss: 0.6593 - acc: 0.722 - 0s 571us/sample - loss: 0.6483 - acc: 0.7333 - val_loss: 0.8251 - val_acc: 0.7500\n",
            "Epoch 36/100\n",
            "345/345 [==============================] - ETA: 0s - loss: 0.5019 - acc: 0.812 - ETA: 0s - loss: 0.5351 - acc: 0.793 - 0s 580us/sample - loss: 0.5563 - acc: 0.7797 - val_loss: 0.7942 - val_acc: 0.7500\n",
            "Epoch 37/100\n",
            "345/345 [==============================] - ETA: 0s - loss: 0.5007 - acc: 0.796 - ETA: 0s - loss: 0.5523 - acc: 0.765 - 0s 578us/sample - loss: 0.5534 - acc: 0.7739 - val_loss: 0.8373 - val_acc: 0.6983\n",
            "Epoch 38/100\n",
            "345/345 [==============================] - ETA: 0s - loss: 0.5256 - acc: 0.812 - ETA: 0s - loss: 0.5363 - acc: 0.773 - 0s 554us/sample - loss: 0.5276 - acc: 0.7826 - val_loss: 1.2355 - val_acc: 0.6121\n",
            "Epoch 39/100\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "345/345 [==============================] - ETA: 0s - loss: 0.5975 - acc: 0.742 - ETA: 0s - loss: 0.7819 - acc: 0.675 - 0s 560us/sample - loss: 0.7331 - acc: 0.6986 - val_loss: 0.8328 - val_acc: 0.7241\n",
            "Epoch 40/100\n",
            "345/345 [==============================] - ETA: 0s - loss: 0.4531 - acc: 0.843 - ETA: 0s - loss: 0.4852 - acc: 0.812 - 0s 595us/sample - loss: 0.4969 - acc: 0.8029 - val_loss: 1.0479 - val_acc: 0.6638\n",
            "Epoch 41/100\n",
            "345/345 [==============================] - ETA: 0s - loss: 0.4831 - acc: 0.820 - ETA: 0s - loss: 0.4770 - acc: 0.816 - 0s 589us/sample - loss: 0.5105 - acc: 0.7884 - val_loss: 0.8516 - val_acc: 0.7672\n",
            "Epoch 42/100\n",
            "345/345 [==============================] - ETA: 0s - loss: 0.7007 - acc: 0.695 - ETA: 0s - loss: 0.6238 - acc: 0.734 - 0s 580us/sample - loss: 0.6054 - acc: 0.7536 - val_loss: 1.2006 - val_acc: 0.6379\n",
            "Epoch 43/100\n",
            "345/345 [==============================] - ETA: 0s - loss: 0.4610 - acc: 0.789 - ETA: 0s - loss: 0.5320 - acc: 0.761 - 0s 606us/sample - loss: 0.5229 - acc: 0.7652 - val_loss: 0.9624 - val_acc: 0.7241\n",
            "Epoch 44/100\n",
            "345/345 [==============================] - ETA: 0s - loss: 0.4613 - acc: 0.812 - ETA: 0s - loss: 0.4319 - acc: 0.832 - 0s 603us/sample - loss: 0.4475 - acc: 0.8232 - val_loss: 0.9708 - val_acc: 0.7586\n",
            "Epoch 45/100\n",
            "345/345 [==============================] - ETA: 0s - loss: 0.5935 - acc: 0.710 - ETA: 0s - loss: 0.5003 - acc: 0.765 - 0s 651us/sample - loss: 0.4804 - acc: 0.7768 - val_loss: 1.0077 - val_acc: 0.6897\n",
            "Epoch 46/100\n",
            "345/345 [==============================] - ETA: 0s - loss: 0.3995 - acc: 0.835 - 0s 506us/sample - loss: 0.4518 - acc: 0.8174 - val_loss: 0.8211 - val_acc: 0.7672\n",
            "Epoch 47/100\n",
            "345/345 [==============================] - ETA: 0s - loss: 0.6406 - acc: 0.671 - ETA: 0s - loss: 0.5592 - acc: 0.757 - 0s 506us/sample - loss: 0.5330 - acc: 0.7681 - val_loss: 1.1169 - val_acc: 0.6293\n",
            "Epoch 48/100\n",
            "345/345 [==============================] - ETA: 0s - loss: 0.3496 - acc: 0.875 - ETA: 0s - loss: 0.3484 - acc: 0.867 - 0s 564us/sample - loss: 0.3501 - acc: 0.8667 - val_loss: 1.0995 - val_acc: 0.7069\n",
            "Epoch 49/100\n",
            "345/345 [==============================] - ETA: 0s - loss: 0.3658 - acc: 0.843 - ETA: 0s - loss: 0.3991 - acc: 0.863 - 0s 525us/sample - loss: 0.4411 - acc: 0.8406 - val_loss: 0.9091 - val_acc: 0.6810\n",
            "Epoch 50/100\n",
            "345/345 [==============================] - ETA: 0s - loss: 0.3743 - acc: 0.882 - 0s 487us/sample - loss: 0.3446 - acc: 0.8754 - val_loss: 1.0533 - val_acc: 0.7155\n",
            "Epoch 51/100\n",
            "345/345 [==============================] - ETA: 0s - loss: 0.3700 - acc: 0.835 - ETA: 0s - loss: 0.3863 - acc: 0.824 - 0s 510us/sample - loss: 0.4382 - acc: 0.8087 - val_loss: 1.2264 - val_acc: 0.6293\n",
            "Epoch 52/100\n",
            "345/345 [==============================] - ETA: 0s - loss: 0.3719 - acc: 0.867 - ETA: 0s - loss: 0.3540 - acc: 0.867 - 0s 510us/sample - loss: 0.3506 - acc: 0.8667 - val_loss: 1.2932 - val_acc: 0.5948\n",
            "Epoch 53/100\n",
            "345/345 [==============================] - ETA: 0s - loss: 0.3450 - acc: 0.843 - ETA: 0s - loss: 0.3584 - acc: 0.839 - 0s 558us/sample - loss: 0.3489 - acc: 0.8522 - val_loss: 1.5277 - val_acc: 0.6121\n",
            "Epoch 54/100\n",
            "345/345 [==============================] - ETA: 0s - loss: 0.4414 - acc: 0.828 - ETA: 0s - loss: 0.4694 - acc: 0.804 - 0s 510us/sample - loss: 0.4421 - acc: 0.8232 - val_loss: 1.0488 - val_acc: 0.7500\n",
            "Epoch 55/100\n",
            "345/345 [==============================] - ETA: 0s - loss: 0.2496 - acc: 0.906 - ETA: 0s - loss: 0.2534 - acc: 0.898 - 0s 510us/sample - loss: 0.2684 - acc: 0.8957 - val_loss: 1.3043 - val_acc: 0.6121\n",
            "Epoch 56/100\n",
            "345/345 [==============================] - ETA: 0s - loss: 0.2765 - acc: 0.867 - ETA: 0s - loss: 0.2913 - acc: 0.898 - 0s 518us/sample - loss: 0.3119 - acc: 0.8957 - val_loss: 1.2862 - val_acc: 0.6466\n",
            "Epoch 57/100\n",
            "345/345 [==============================] - ETA: 0s - loss: 0.2691 - acc: 0.906 - ETA: 0s - loss: 0.2615 - acc: 0.902 - 0s 516us/sample - loss: 0.2999 - acc: 0.8754 - val_loss: 1.0507 - val_acc: 0.7672\n",
            "Epoch 58/100\n",
            "345/345 [==============================] - ETA: 0s - loss: 0.6334 - acc: 0.695 - 0s 487us/sample - loss: 0.4483 - acc: 0.8000 - val_loss: 1.5125 - val_acc: 0.5517\n",
            "Epoch 59/100\n",
            "345/345 [==============================] - ETA: 0s - loss: 0.2678 - acc: 0.937 - 0s 482us/sample - loss: 0.2219 - acc: 0.9536 - val_loss: 1.3279 - val_acc: 0.7414\n",
            "Epoch 60/100\n",
            "345/345 [==============================] - ETA: 0s - loss: 0.3378 - acc: 0.835 - ETA: 0s - loss: 0.3374 - acc: 0.863 - 0s 542us/sample - loss: 0.3267 - acc: 0.8725 - val_loss: 1.3574 - val_acc: 0.6810\n",
            "Epoch 61/100\n",
            "345/345 [==============================] - ETA: 0s - loss: 0.2228 - acc: 0.921 - ETA: 0s - loss: 0.2082 - acc: 0.937 - 0s 470us/sample - loss: 0.1916 - acc: 0.9449 - val_loss: 1.5005 - val_acc: 0.6983\n",
            "Epoch 62/100\n",
            "345/345 [==============================] - ETA: 0s - loss: 0.1527 - acc: 0.937 - ETA: 0s - loss: 0.1464 - acc: 0.949 - 0s 459us/sample - loss: 0.1721 - acc: 0.9391 - val_loss: 1.1816 - val_acc: 0.7241\n",
            "Epoch 63/100\n",
            "345/345 [==============================] - ETA: 0s - loss: 0.5198 - acc: 0.750 - ETA: 0s - loss: 0.4648 - acc: 0.789 - 0s 465us/sample - loss: 0.4740 - acc: 0.7942 - val_loss: 1.1369 - val_acc: 0.6293\n",
            "Epoch 64/100\n",
            "345/345 [==============================] - ETA: 0s - loss: 0.2957 - acc: 0.906 - ETA: 0s - loss: 0.2680 - acc: 0.914 - 0s 468us/sample - loss: 0.2402 - acc: 0.9275 - val_loss: 1.4971 - val_acc: 0.6466\n",
            "Epoch 65/100\n",
            "345/345 [==============================] - ETA: 0s - loss: 0.1680 - acc: 0.921 - ETA: 0s - loss: 0.1786 - acc: 0.929 - 0s 469us/sample - loss: 0.2097 - acc: 0.9101 - val_loss: 1.5838 - val_acc: 0.6121\n",
            "Epoch 66/100\n",
            "345/345 [==============================] - ETA: 0s - loss: 0.1882 - acc: 0.945 - ETA: 0s - loss: 0.2070 - acc: 0.933 - 0s 464us/sample - loss: 0.1946 - acc: 0.9362 - val_loss: 1.9997 - val_acc: 0.5776\n",
            "Epoch 67/100\n",
            "345/345 [==============================] - ETA: 0s - loss: 0.2332 - acc: 0.898 - ETA: 0s - loss: 0.3296 - acc: 0.886 - 0s 487us/sample - loss: 0.2910 - acc: 0.9101 - val_loss: 2.1446 - val_acc: 0.5690\n",
            "Epoch 68/100\n",
            "345/345 [==============================] - ETA: 0s - loss: 0.1732 - acc: 0.929 - 0s 441us/sample - loss: 0.3294 - acc: 0.8435 - val_loss: 1.0496 - val_acc: 0.7672\n",
            "Epoch 69/100\n",
            "345/345 [==============================] - ETA: 0s - loss: 0.5934 - acc: 0.757 - ETA: 0s - loss: 0.4611 - acc: 0.832 - 0s 487us/sample - loss: 0.3933 - acc: 0.8522 - val_loss: 1.5867 - val_acc: 0.6034\n",
            "Epoch 70/100\n",
            "345/345 [==============================] - ETA: 0s - loss: 0.1593 - acc: 0.960 - 0s 464us/sample - loss: 0.1636 - acc: 0.9507 - val_loss: 1.5425 - val_acc: 0.6724\n",
            "Epoch 71/100\n",
            "345/345 [==============================] - ETA: 0s - loss: 0.1366 - acc: 0.976 - 0s 464us/sample - loss: 0.1459 - acc: 0.9623 - val_loss: 2.0495 - val_acc: 0.5690\n",
            "Epoch 72/100\n",
            "345/345 [==============================] - ETA: 0s - loss: 0.1299 - acc: 0.976 - ETA: 0s - loss: 0.1375 - acc: 0.953 - 0s 487us/sample - loss: 0.1417 - acc: 0.9565 - val_loss: 1.4072 - val_acc: 0.6983\n",
            "Epoch 73/100\n",
            "345/345 [==============================] - ETA: 0s - loss: 0.1687 - acc: 0.914 - 0s 441us/sample - loss: 0.1784 - acc: 0.9275 - val_loss: 2.2492 - val_acc: 0.5345\n",
            "Epoch 74/100\n",
            "345/345 [==============================] - ETA: 0s - loss: 0.5515 - acc: 0.757 - 0s 441us/sample - loss: 0.4223 - acc: 0.8232 - val_loss: 1.4459 - val_acc: 0.6897\n",
            "Epoch 75/100\n",
            "345/345 [==============================] - ETA: 0s - loss: 0.1784 - acc: 0.929 - ETA: 0s - loss: 0.1540 - acc: 0.953 - 0s 464us/sample - loss: 0.1460 - acc: 0.9594 - val_loss: 1.8539 - val_acc: 0.5776\n",
            "Epoch 76/100\n",
            "345/345 [==============================] - ETA: 0s - loss: 0.0690 - acc: 1.000 - ETA: 0s - loss: 0.0681 - acc: 0.992 - 0s 464us/sample - loss: 0.0780 - acc: 0.9855 - val_loss: 2.4827 - val_acc: 0.5345\n",
            "Epoch 77/100\n",
            "345/345 [==============================] - ETA: 0s - loss: 0.2632 - acc: 0.898 - 0s 464us/sample - loss: 0.2479 - acc: 0.9159 - val_loss: 1.6720 - val_acc: 0.6638\n",
            "Epoch 78/100\n",
            "345/345 [==============================] - ETA: 0s - loss: 0.0923 - acc: 0.976 - ETA: 0s - loss: 0.0922 - acc: 0.972 - 0s 701us/sample - loss: 0.0819 - acc: 0.9739 - val_loss: 2.1081 - val_acc: 0.6207\n",
            "Epoch 79/100\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "345/345 [==============================] - ETA: 0s - loss: 0.0701 - acc: 0.992 - ETA: 0s - loss: 0.0537 - acc: 0.996 - 0s 720us/sample - loss: 0.0490 - acc: 0.9971 - val_loss: 2.0446 - val_acc: 0.6724\n",
            "Epoch 80/100\n",
            "345/345 [==============================] - ETA: 0s - loss: 0.0230 - acc: 1.000 - ETA: 0s - loss: 0.0246 - acc: 1.000 - 0s 591us/sample - loss: 0.0290 - acc: 0.9971 - val_loss: 2.2824 - val_acc: 0.6121\n",
            "Epoch 81/100\n",
            "345/345 [==============================] - ETA: 0s - loss: 0.0239 - acc: 1.000 - ETA: 0s - loss: 0.0248 - acc: 1.000 - 0s 568us/sample - loss: 0.0360 - acc: 0.9913 - val_loss: 2.8940 - val_acc: 0.5086\n",
            "Epoch 82/100\n",
            "345/345 [==============================] - ETA: 0s - loss: 0.3202 - acc: 0.875 - ETA: 0s - loss: 0.9887 - acc: 0.781 - 0s 1ms/sample - loss: 0.8400 - acc: 0.7913 - val_loss: 1.4187 - val_acc: 0.7672\n",
            "Epoch 83/100\n",
            "345/345 [==============================] - ETA: 0s - loss: 0.7276 - acc: 0.742 - ETA: 0s - loss: 0.4807 - acc: 0.828 - 0s 670us/sample - loss: 0.4167 - acc: 0.8464 - val_loss: 1.9395 - val_acc: 0.5690\n",
            "Epoch 84/100\n",
            "345/345 [==============================] - ETA: 0s - loss: 0.0951 - acc: 0.992 - ETA: 0s - loss: 0.0844 - acc: 0.992 - 0s 533us/sample - loss: 0.0757 - acc: 0.9942 - val_loss: 1.9602 - val_acc: 0.5862\n",
            "Epoch 85/100\n",
            "345/345 [==============================] - ETA: 0s - loss: 0.0400 - acc: 1.000 - 0s 483us/sample - loss: 0.0409 - acc: 0.9971 - val_loss: 2.1747 - val_acc: 0.5948\n",
            "Epoch 86/100\n",
            "345/345 [==============================] - ETA: 0s - loss: 0.0347 - acc: 1.000 - ETA: 0s - loss: 0.0340 - acc: 1.000 - 0s 501us/sample - loss: 0.0319 - acc: 1.0000 - val_loss: 2.2594 - val_acc: 0.5948\n",
            "Epoch 87/100\n",
            "345/345 [==============================] - ETA: 0s - loss: 0.0225 - acc: 1.000 - 0s 484us/sample - loss: 0.0230 - acc: 1.0000 - val_loss: 2.1552 - val_acc: 0.6034\n",
            "Epoch 88/100\n",
            "345/345 [==============================] - ETA: 0s - loss: 0.0224 - acc: 1.000 - ETA: 0s - loss: 0.0212 - acc: 1.000 - 0s 531us/sample - loss: 0.0196 - acc: 1.0000 - val_loss: 2.2420 - val_acc: 0.5948\n",
            "Epoch 89/100\n",
            "345/345 [==============================] - ETA: 0s - loss: 0.0150 - acc: 1.000 - ETA: 0s - loss: 0.0151 - acc: 1.000 - 0s 506us/sample - loss: 0.0144 - acc: 1.0000 - val_loss: 2.4006 - val_acc: 0.5862\n",
            "Epoch 90/100\n",
            "345/345 [==============================] - ETA: 0s - loss: 0.0115 - acc: 1.000 - 0s 489us/sample - loss: 0.0121 - acc: 1.0000 - val_loss: 2.2648 - val_acc: 0.6207\n",
            "Epoch 91/100\n",
            "345/345 [==============================] - ETA: 0s - loss: 0.0122 - acc: 1.000 - ETA: 0s - loss: 0.0128 - acc: 1.000 - 0s 533us/sample - loss: 0.0161 - acc: 1.0000 - val_loss: 3.4084 - val_acc: 0.5000\n",
            "Epoch 92/100\n",
            "345/345 [==============================] - ETA: 0s - loss: 0.1520 - acc: 0.945 - ETA: 0s - loss: 0.7894 - acc: 0.812 - 0s 517us/sample - loss: 0.7501 - acc: 0.7884 - val_loss: 1.1573 - val_acc: 0.7414\n",
            "Epoch 93/100\n",
            "345/345 [==============================] - ETA: 0s - loss: 0.4428 - acc: 0.828 - ETA: 0s - loss: 0.3892 - acc: 0.851 - 0s 580us/sample - loss: 0.3645 - acc: 0.8493 - val_loss: 1.9791 - val_acc: 0.5690\n",
            "Epoch 94/100\n",
            "345/345 [==============================] - ETA: 0s - loss: 0.1006 - acc: 0.984 - ETA: 0s - loss: 0.0984 - acc: 0.984 - 0s 517us/sample - loss: 0.0885 - acc: 0.9884 - val_loss: 1.9385 - val_acc: 0.6207\n",
            "Epoch 95/100\n",
            "345/345 [==============================] - ETA: 0s - loss: 0.0498 - acc: 0.992 - ETA: 0s - loss: 0.0390 - acc: 0.996 - 0s 508us/sample - loss: 0.0399 - acc: 0.9971 - val_loss: 2.0133 - val_acc: 0.6293\n",
            "Epoch 96/100\n",
            "345/345 [==============================] - ETA: 0s - loss: 0.0300 - acc: 1.000 - ETA: 0s - loss: 0.0252 - acc: 1.000 - 0s 580us/sample - loss: 0.0262 - acc: 1.0000 - val_loss: 2.3207 - val_acc: 0.6121\n",
            "Epoch 97/100\n",
            "345/345 [==============================] - ETA: 0s - loss: 0.0150 - acc: 1.000 - ETA: 0s - loss: 0.0164 - acc: 1.000 - 0s 554us/sample - loss: 0.0161 - acc: 1.0000 - val_loss: 2.3782 - val_acc: 0.6121\n",
            "Epoch 98/100\n",
            "345/345 [==============================] - ETA: 0s - loss: 0.0128 - acc: 1.000 - ETA: 0s - loss: 0.0122 - acc: 1.000 - 0s 579us/sample - loss: 0.0117 - acc: 1.0000 - val_loss: 2.5017 - val_acc: 0.6121\n",
            "Epoch 99/100\n",
            "345/345 [==============================] - ETA: 0s - loss: 0.0098 - acc: 1.000 - ETA: 0s - loss: 0.0092 - acc: 1.000 - 0s 531us/sample - loss: 0.0089 - acc: 1.0000 - val_loss: 2.5307 - val_acc: 0.6207\n",
            "Epoch 100/100\n",
            "345/345 [==============================] - ETA: 0s - loss: 0.0071 - acc: 1.000 - ETA: 0s - loss: 0.0078 - acc: 1.000 - 0s 557us/sample - loss: 0.0075 - acc: 1.0000 - val_loss: 2.6095 - val_acc: 0.6121\n",
            "116/116 [==============================] - 0s 143us/sample - loss: 2.6095 - acc: 0.6121\n",
            "Summary: Loss over the test dataset: 2.61, Accuracy: 0.61\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zTaH0ta_9XfM"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}